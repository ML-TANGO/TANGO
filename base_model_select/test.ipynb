{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753062c-49c9-4f4d-8942-abf15c2aced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "Find out sources of randomness and figure out overall accuracy\n",
    "Try entropy method/something more lightweight?\n",
    "Stricter definition of 'correct' needed?\n",
    "Possible to train neural netowkr to err on side of caution?\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib widget\n",
    "\n",
    "# Important\n",
    "import torch\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.stats import entropy\n",
    "import skimage.measure    \n",
    "\n",
    "\n",
    "# Dev utility\n",
    "import warnings\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "\n",
    "from cProfile import Profile\n",
    "from pstats import SortKey, Stats\n",
    "\n",
    "\n",
    "\n",
    "#Pytorch specific\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# User made\n",
    "from detector import YOLOv7ObjectDetector\n",
    "from classes import *\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a275e-9b66-4a5b-b323-e79f91720a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"CUDA is not available, exiting\")\n",
    "    exit()\n",
    "\n",
    "data_loader_wrapper = DataLoaderWrapper()\n",
    "\n",
    "# Predictor list\n",
    "\n",
    "models = [\n",
    "    \"yolov7\",\n",
    "    \"yolov7x\",\n",
    "    \"yolov7-tiny\",\n",
    "    \"yolov7-w6\",\n",
    "    \"yolov7-e6\",\n",
    "    \"yolov7-d6\",\n",
    "    \"yolov7-e6e\",\n",
    "]\n",
    "\n",
    "models_pt = [model + \".pt\" for model in models]\n",
    "print(models_pt)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"yolov7\")\n",
    "# from models.experimental import attempt_load\n",
    "\n",
    "# attempt_load(models_pt)\n",
    "\n",
    "predictor_list = [YOLOv7ObjectDetector(model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78ebb0-8b35-4cd3-ac33-b7ce18e3703e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def selector(path):  \n",
    "    img = Image.open(path)\n",
    "    yPieces = 3\n",
    "    xPieces = 3 \n",
    "    \n",
    "    entropies = []\n",
    "    imgwidth, imgheight = img.size\n",
    "    height = imgheight // yPieces\n",
    "    width = imgwidth // xPieces\n",
    "    for i in range(0, yPieces):\n",
    "        for j in range(0, xPieces):\n",
    "            box = (j * width, i * height, (j + 1) * width, (i + 1) * height)\n",
    "            section = img.crop(box)\n",
    "            entropies.append(section.entropy())\n",
    "\n",
    "    # Output must be a numpy array\n",
    "    return np.array(entropies, dtype=np.float32)\n",
    "\n",
    "\n",
    "def label_data(data_loader):\n",
    "        \n",
    "    ref_predictor = predictor_list[-1]          # Pick reference predictor\n",
    "\n",
    "    ref_predictor._model.to(DEVICE)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    append_data = []\n",
    "    data = [[] for i in range(len(predictor_list))]\n",
    "    for img_path_list in tqdm(data_loader):\n",
    "        \n",
    "        img_path = img_path_list[0]                 # Load an image        \n",
    "        ref_res = ref_predictor.detect(img_path)    # Get reference data\n",
    "        \n",
    "        #Accumulate all the classes detected\n",
    "        ref_aggregrate = dict()\n",
    "        for cls in ref_res:\n",
    "            if cls in ref_aggregrate:\n",
    "                ref_aggregrate[cls] += 1\n",
    "            else:\n",
    "                ref_aggregrate[cls] = 1\n",
    "\n",
    "                        \n",
    "        for i, predictor in enumerate(predictor_list):\n",
    "            res = predictor.detect(img_path)\n",
    "            \n",
    "            \n",
    "            result_aggregrate = dict()\n",
    "            for cls in res:\n",
    "                if cls in result_aggregrate:\n",
    "                    result_aggregrate[cls] += 1\n",
    "                else:\n",
    "                    result_aggregrate[cls] = 1\n",
    "\n",
    "            \n",
    "            # If the model data is the same as the reference data AND we meet the predicate\n",
    "            if ref_aggregrate == result_aggregrate:\n",
    "                ## Add feature and indexed model to the dataframe\n",
    "                append_data.append({\n",
    "                    \"feat\": selector(img_path),\n",
    "                    \"label\": i,\n",
    "                })\n",
    "                break\n",
    "\n",
    "    if append_data:\n",
    "        df = pd.concat([df, pd.DataFrame(append_data)], ignore_index=True)\n",
    "\n",
    "\n",
    "    return PandasDataset(df, len(predictor_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bee6ab-e07b-4157-a377-a5d55a2e7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "\n",
    "class SVMPredictor():\n",
    "    def __init__(self, input_size=None, output_size=None, pt=\"\"):\n",
    "        super(SVMPredictor, self).__init__()\n",
    "        if pt == \"\":\n",
    "            self._model = nn.Sequential(\n",
    "                nn.Linear(input_size, output_size),\n",
    "            )\n",
    "        else:\n",
    "            # pt \n",
    "            self._model = nn.Sequential(nn.Linear(input_size, output_size))\n",
    "            self._model.load_state_dict(torch.load(pt))\n",
    "            \n",
    "        self.sizes = (input_size, output_size)\n",
    "\n",
    "        self.stats = [0 for x in range(output_size)]\n",
    "        \n",
    "        self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self._model.to(self._device)\n",
    "\n",
    "        self._best_acc = 0\n",
    "        self._name = \"SVM\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "        \n",
    "    def _train(self, data_loader):\n",
    "        self._model.train()\n",
    "\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(\n",
    "            self._model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4\n",
    "        )\n",
    "        \n",
    "        first = False\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader.get_train_loader()):\n",
    "            \n",
    "            # Moves tensor to device GPU/CPU\n",
    "            inputs, targets = inputs.to(self._device), targets.to(self._device) \n",
    "\n",
    "            outputs = self._model(inputs)       # Forward Pass\n",
    "            loss = criterion(outputs, targets)  # Calculate loss\n",
    "            \n",
    "            optimizer.zero_grad()               # Optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Compare predicted and actual results\n",
    "            predicted = (torch.argmax(outputs[0])).item()\n",
    "            actual = (torch.argmax(targets[0])).item()\n",
    "\n",
    "            # print(predicted, actual)\n",
    "            \n",
    "            # Used to calculate accuracy                        \n",
    "            total += 1\n",
    "            correct += (predicted == actual)            \n",
    "\n",
    "    def _test(self, data_loader):\n",
    "        self._model.eval()\n",
    "\n",
    "        test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(data_loader.get_test_loader()):\n",
    "                \n",
    "                inputs, targets = inputs.to(self._device), targets.to(self._device)\n",
    "                # print(inputs)\n",
    "                outputs = self._model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # print(outputs)\n",
    "                # print(outputs[0])\n",
    "                \n",
    "                predicted = (torch.argmax(outputs[0])).item()\n",
    "                actual = (torch.argmax(targets[0])).item()\n",
    "\n",
    "                self.stats[predicted] += 1\n",
    "            \n",
    "                total += 1\n",
    "                correct += (predicted >= actual)\n",
    "\n",
    "        acc = 100.0 * correct / total\n",
    "        if acc > self._best_acc:\n",
    "            # print(\"Saving..\", acc)\n",
    "            state = {\n",
    "                \"model\": self._model.state_dict(),\n",
    "                \"acc\": acc,\n",
    "            }\n",
    "            if not os.path.isdir(\"checkpoint\"):\n",
    "                os.mkdir(\"checkpoint\")\n",
    "            torch.save(state, \"./checkpoint/{}_ckpt.pth\".format(self._name))\n",
    "            self._best_acc = acc\n",
    "            \n",
    "        return correct == total\n",
    "\n",
    "    def train(self, data_loader, epoch=5):\n",
    "        for e in range(epoch):\n",
    "            self._train(data_loader)\n",
    "            if e % 5 == 0:\n",
    "                self._test(data_loader)\n",
    "                # break\n",
    "                # print(f\"Early stopping at epoch {e}\")\n",
    "\n",
    "        self.print_stats()\n",
    "        return self._best_acc\n",
    "        \n",
    "    def parse(self, path):\n",
    "        import xml.etree.ElementTree as ET\n",
    "\n",
    "        # parse xml file\n",
    "        tree = ET.parse(path) \n",
    "        root = tree.getroot() # get root object\n",
    "        \n",
    "        height = int(root.find(\"size\")[0].text)\n",
    "        width = int(root.find(\"size\")[1].text)\n",
    "        channels = int(root.find(\"size\")[2].text)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        names = [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "         'hair drier', 'toothbrush' ]\n",
    "        named = {}\n",
    "        for i, name in enumerate(names):\n",
    "            named[name] = i\n",
    "        \n",
    "        for member in root.findall('object'):\n",
    "            class_name = member[0].text # class name\n",
    "                \n",
    "            if class_name not in named:\n",
    "                continue\n",
    "            \n",
    "            # bbox coordinates\n",
    "            xmin = int(member[4][0].text)\n",
    "            ymin = int(member[4][1].text)\n",
    "            xmax = int(member[4][2].text)\n",
    "            ymax = int(member[4][3].text)\n",
    "            # store data in list\n",
    "            labels.append(named[class_name])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        return [{\n",
    "            \"boxes\": torch.FloatTensor(boxes),\n",
    "            \"labels\": torch.as_tensor(labels),\n",
    "        }]\n",
    "    \n",
    "    def process_data(self, data_loader):\n",
    "        df = pd.DataFrame()\n",
    "        append_data = []\n",
    "        for img_path_list in data_loader:\n",
    "            img_path = img_path_list[0]                 # Load an image\n",
    "            append_data.append({\n",
    "                \"path\": img_path,\n",
    "                \"feat\": selector(img_path)\n",
    "            })\n",
    "        df = pd.concat([df, pd.DataFrame(append_data)], ignore_index=True)\n",
    "        return PandasTest(df, len(predictor_list))\n",
    "    \n",
    "    def pad(self, data_loader):\n",
    "        df = pd.DataFrame()\n",
    "        append_data = []\n",
    "        for img_path_list in data_loader:\n",
    "            img_path = img_path_list[0]                 # Load an image\n",
    "            append_data.append({\n",
    "                \"path\": img_path,\n",
    "                \"feat\": np.zeros(6)\n",
    "            })\n",
    "        df = pd.concat([df, pd.DataFrame(append_data)], ignore_index=True)\n",
    "        return PandasTest(df, len(predictor_list))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, test_dataset, bias=None, random=False):\n",
    "        self._model.eval()\n",
    "        from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "        map = MeanAveragePrecision(box_format=\"xyxy\")\n",
    "        \n",
    "        t1 = time.process_time()\n",
    "        if bias is None:\n",
    "            test_set = self.process_data(DataLoader(test_dataset, shuffle=True))\n",
    "        else:\n",
    "            test_set = self.pad(DataLoader(test_dataset, shuffle=True))\n",
    "            \n",
    "        t2 = time.process_time()\n",
    "        print(f\"Pre-processing time: {(t2-t1):.3f}\")\n",
    "\n",
    "        \n",
    "        # feature_extractor = ResNet18Extractor() #Auto puts into CUDA\n",
    "\n",
    "        t1 = time.process_time()\n",
    "\n",
    "        for batch_idx, (feat, img_path) in enumerate(DataLoader(test_set)):\n",
    "            \n",
    "            path = img_path[0]\n",
    "            \n",
    "            \n",
    "            if bias is None:\n",
    "                feat = feat.to(self._device)                \n",
    "                outputs = self._model(feat)       # Forward Pass            \n",
    "                # Compare predicted and actual results\n",
    "                pred_indx = (torch.argmax(outputs[0])).item()\n",
    "            elif random:\n",
    "                pred_indx = random.randint(0, len(predictor_list)-1)\n",
    "                print(pred_indx)\n",
    "            else:\n",
    "                pred_indx = bias\n",
    "                \n",
    "            result = predictor_list[pred_indx].detect_(path)\n",
    "            out = result.pandas().xyxy[0]\n",
    "            # print(out)\n",
    "            if out.empty:\n",
    "                preds = [\n",
    "                    {\n",
    "                        \"boxes\": torch.FloatTensor([]),\n",
    "                        \"scores\": torch.FloatTensor([]),\n",
    "                        \"labels\": torch.FloatTensor([]),\n",
    "                    }\n",
    "                ]\n",
    "            else:\n",
    "                preds = [\n",
    "                    {\n",
    "                        \"boxes\": torch.FloatTensor(out.iloc[:, :4].values),\n",
    "                        \"scores\": torch.FloatTensor(out.loc[:, \"confidence\"].values),\n",
    "                        \"labels\": torch.tensor(out.loc[:, \"class\"].values),\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "            # preds = self.get_preds(result.pandas().xyxy[0])\n",
    "            # print(preds)\n",
    "            \n",
    "            path = Path(path)\n",
    "            ann_path = path.parent.parent / \"Annotations\" / (path.name.split(\".\")[0] + \".xml\")\n",
    "            # print(ann_path)\n",
    "            if ann_path.exists():\n",
    "                targets = self.parse(ann_path)\n",
    "                map.update(preds, targets)\n",
    "            else:\n",
    "                print(f\"{str(ann_path)} was not found\")\n",
    "                    \n",
    "        t2 = time.process_time()\n",
    "        print(f\"Inference time: {(t2-t1):.3f}\")\n",
    "            \n",
    "        print(f\"mAP: {map.compute()['map'].item():.3f}\")\n",
    "\n",
    "        return map.compute()['map'].item()\n",
    "\n",
    "    def print_stats(self):\n",
    "        total = 0\n",
    "        print(\"Model selection percentages\")\n",
    "        for i in range(len(self.stats)):\n",
    "            total += self.stats[i]\n",
    "\n",
    "        for i in range(len(self.stats)):\n",
    "            print(f\"{i}: {self.stats[i]/total}\")   \n",
    "        \n",
    "        print(f\"{self._best_acc:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1843d4e-8de6-418b-b0f1-c036fbda60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "tr_sz = int(N * .6)\n",
    "va_sz = int(N * .2)\n",
    "ta_sz = int(N * .2)\n",
    "\n",
    "dataset = VOCDetection(root=\".\", year=\"2012\", image_set=\"val\", download=not Path(\"VOCdevkit\").exists())\n",
    "dataset = Subset(dataset, range(N))\n",
    "train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, [tr_sz, va_sz, ta_sz])\n",
    "\n",
    "\n",
    "train_pandas_dataset = label_data(DataLoader(train_dataset, shuffle=True))\n",
    "\n",
    "val_set = label_data(DataLoader(validation_dataset, shuffle=True))\n",
    "\n",
    "\n",
    "data_loader_wrapper.set_train_loader(train_pandas_dataset)\n",
    "data_loader_wrapper.set_test_loader(val_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036a023-68cc-437a-9ed7-5dd5bf9c7247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat = train_pandas_dataset._df[\"feat\"].to_numpy()[0]\n",
    "feat_size = np.prod(feat.shape)\n",
    "# print(torch.flatten(torch.tensor(feat)))\n",
    "# print(feat, feat_size)\n",
    "# print(\"Input: \", train_pandas_dataset.feat_size, \"Output: \", len(predictor_list))\n",
    "model_predictor = SVMPredictor(train_pandas_dataset.feat_size, len(predictor_list))\n",
    "acc = model_predictor.train(data_loader_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090e24a-03a1-43d3-b389-6b704d1a2d11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# for i in range(len(predictor_list)):\n",
    "#     print(f\"Always use {i+1}th smallest model\")\n",
    "#     t1 = time.process_time()\n",
    "#     mapi = model_predictor.test(test_dataset, i)\n",
    "#     t2 = time.process_time()\n",
    "#     diff = t2 - t1\n",
    "#     print(f\"Time Taken: {diff:.3f} map/time {mapi / diff:.3f}\\n\")\n",
    "\n",
    "# print(\"Use dynamic selector model\")\n",
    "# t1 = time.process_time()\n",
    "# mapi = model_predictor.test(test_dataset)\n",
    "# t2 = time.process_time()\n",
    "# diff = t2 - t1\n",
    "# print(f\"Time Taken: {diff:.3f} map/time {mapi / diff:.3f}\\n\")\n",
    "\n",
    "\n",
    "# print(\"Use random selector model\")\n",
    "# t1 = time.process_time()\n",
    "# mapi = model_predictor.test(test_dataset, random=True)\n",
    "# t2 = time.process_time()\n",
    "# diff = t2 - t1\n",
    "# print(f\"Time Taken: {diff:.3f} map/time {mapi / diff:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model_predictor._model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model_predictor._model.state_dict()[param_tensor].size())\n",
    "\n",
    "torch.save(model_predictor._model.state_dict(), \"test.pt\")\n",
    "\n",
    "print(train_pandas_dataset.feat_size, len(predictor_list))\n",
    "\n",
    "model_predictor = SVMPredictor(train_pandas_dataset.feat_size, len(predictor_list), \"test.pt\")\n",
    "model_predictor._model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdad1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
