# 'neural_net_info.yaml'
# meta file from auto_nn

# NN Model
class_file: 'bestmodel.py' # for pytorch model
class_name: 'TheBestmodelClass()' # for pytorch model
weight_file: [bestmodel.pt, yolo5s.onnx]

# in case of 'pytorch'-type model usage ex.
# model = TheBestModelClass() # this class is in the python file 'bestmodel.py'
# model.load_state_dict(torch.load('bestmodel.pt'))
# model.eval()
# khlee: basically .pt, .py which has pre&post processing functions so that no need to consider them-> use such as mode.render withod post processing function
# if one uses onnx, he should use pre & post processing functions -> suck as in RKNN processing


# Label
nc: 80 # number of classes
label_info_file: labelmap.yaml

# labelmap.yaml ex.
# nc: 80 # number of classes
# names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
#          'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
#          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
#          'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
#          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
#          'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
#          'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
#          'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
#          'hair drier', 'toothbrush' ]
# task: detection



# Input
input_tensor_shape: [1, 3, 640, 640]
input_data_type: fp32 # fp32, fp16, int8, etc
# anchors: 3
anchors:
  - [10,13, 16,30, 33,23]  # P3
  - [30,61, 62,45, 59,119]  # P4
  - [116,90, 156,198, 373,326]  # P5



# Pre-processing
vision_lib: cv2 # OpenCV
norm: [255, 255, 255] # 0 ~ 255 to 0.0 ~ 1.0 (need to divide by 255.0 on each channel)
mean: [0.0, 0.0, 0.0]

# pre-processing ex.
# img = img.to(device) # cpu or gpu
# img = img.float() # uint8 to fp32
# img = img / 255.0 # normalize 0~255 to 0.0~1.0



# Output
output_format_allow_list: True # mutiple detection per image
output_number: 3 # number of output layers (ex. 3-floor pyramid; P3, P4, P5)
output_size: # [outputname, batch_size, anchors, pred, height, width]
  [[1, 1, 3, 20, 20, 85],
   [1, 1, 3, 40, 40, 85],
   [1, 1, 3, 80, 80, 85],
  ]
output_pred_format: # 85 = 4(coordinate) + 1(confidence score) + 80(probablity of classes)
  ['x', 'y', 'w', 'h', 'confidence', 'probability_of_classes']



# Post-processing
conf_thres: 0.25 # for NMS
iou_thres: 0.45 # for NMS
need_nms: True # need to add non-maximum suppression(NMS) codes

