# version: "3"

services:
  #---------------------------------
  # Project Manager
  #---------------------------------
  project_manager:
    build:
      context: ./project_manager
    # command: >
    #   sh -c "chmod 777 ./wait_for_postgres.sh &&
    #          ./wait_for_postgres.sh &&
    #          python manage.py makemigrations tango &&
    #          python manage.py makemigrations datasets &&
    #          python manage.py makemigrations targets &&
    #          python manage.py migrate &&
    #          python manage.py runserver 0.0.0.0:8085"
    command: >
      sh -c "chmod 777 ./wait_for_postgres.sh &&
             ./wait_for_postgres.sh &&
             python manage.py migrate &&
             python manage.py loaddata base_model_data.json &&
             python manage.py runserver 0.0.0.0:8085"
    volumes:
      # - ./project_manager:/code
      - shared:/shared
      - ${COCODIR:-./autonn/autonn/autonn_core/datasets/coco}:/shared/datasets/coco
      - ${COCO128DIR:-./autonn/autonn/autonn_core/datasets/coco128}:/shared/datasets/coco128
      - /var/run/docker.sock:/var/run/docker.sock
    hostname: projectmanager
    ports:
      - "8085:8085"
    environment:
      - POSTGRES_NAME=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    depends_on:
      - postgresql

  #---------------------------------
  # DB for Project Manager
  #---------------------------------
  postgresql:
    image: postgres:15.4
    restart: always
    volumes:
      - postgreSQL:/var/lib/postgresql/data
    environment:
      - POSTGRES_NAME=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres

  #---------------------------------
  # DB for labelling tool
  #---------------------------------
  # mariadb:
  #   container_name: "mariadb"
  #   image: mariadb:10
  #   ports:
  #     - 3306:3306
  #   volumes:
  #     - "./labelling/Deployment/db/my.cnf:/etc/mysql/my.cnf"
  #     - "./labelling/data:/var/lib/mysql"
  #     - "./labelling/Deployment/test/:/docker-entrypoint-initdb.d/"
  #   environment:
  #     MARIADB_DATABASE: labelling
  #     MARIADB_USER: username
  #     MARIADB_PASSWORD: password
  #     MARIADB_ROOT_PASSWORD: password
  #   restart: always

  #---------------------------------
  # Labelling tool
  #---------------------------------
  labelling:
    build:
      context: ./labelling
    volumes:
      - ./labelling/dataset:/var/appdata
      - ./labelling/datadb:/var/lib/mysql
      - shared:/shared
    ports:
      - "8086:80" # for Web UI
      - "8095:10236" # for Rest API

  #---------------------------------
  # AutoNN: AutoNN
  #---------------------------------
  autonn:
    build:
      context: ./autonn/autonn
    shm_size: "256M"
    ipc: host
    command: >
      sh -c "python manage.py makemigrations &&
             python manage.py migrate &&
             python manage.py runserver 0.0.0.0:8100"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
                - utility
                - compute
                - video
    environment:
      - NVIDIA_VISIBLE_DEVICES=${GPU_NUM:-all}
    volumes:
      - ./autonn/autonn:/source
      - shared:/shared
      - ${COCODIR:-./autonn/autonn/autonn_core/datasets/coco}:/shared/datasets/coco
      - ${COCO128DIR:-./autonn/autonn/autonn_core/datasets/coco128}:/shared/datasets/coco128
    hostname: autonn
    ports:
      - "8100:8100" # visualizer (vision model)
      - "8101:8101" # streamlit  (llm)

  #---------------------------------
  # Base Model Selector
  #---------------------------------
  # bms:
  #   build:
  #     context: ./base_model_select
  #   shm_size: "256M"
  #   command: >
  #     sh -c "python manage.py makemigrations &&
  #            python manage.py migrate --run-syncdb &&
  #            python manage.py runserver 0.0.0.0:8081"
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             capabilities:
  #               - gpu
  #               - utility
  #               - compute
  #               - video
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=${GPU_NUM:-all}
  #   hostname: bms
  #   volumes:
  #     - ./base_model_select:/source
  #     - shared:/shared
  #   ports:
  #     - "8081:8081"

  # #---------------------------------
  # # AutoNN: Bakcbone-NAS
  # #---------------------------------
  # autonn_bb:
  #   build:
  #     context: ./autonn/backbone_nas
  #   shm_size: '256M'
  #   ipc: host
  #   command: >
  #     sh -c "python manage.py makemigrations &&
  #            python manage.py migrate &&
  #            python manage.py runserver 0.0.0.0:8087"
  #   # use the below lines commented out if you want to use gpu
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           capabilities:
  #   #             - gpu
  #   #             - utility
  #   #             - compute
  #   #             - video
  #   # environment:
  #   #   - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./autonn/backbone_nas:/source
  #     - shared:/shared
  #   ports:
  #     - "8087:8087"

  # #---------------------------------
  # # AutoNN: Neck-NAS
  # #---------------------------------
  # autonn_nk:
  #   build:
  #     context: ./autonn/neck_nas
  #   shm_size: '256M'
  #   ipc: host
  #   command: >
  #     sh -c "python manage.py makemigrations &&
  #            python manage.py migrate &&
  #            python manage.py runserver 0.0.0.0:8089"
  #   # use the below lines commented out if you want to use gpu
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           capabilities:
  #   #             - gpu
  #   #             - utility
  #   #             - compute
  #   #             - video
  #   # environment:
  #   #   - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./autonn/neck_nas:/source
  #     - shared:/shared
  #     # - /Data:/shared/datasets # for local tests
  #   ports:
  #     - "8089:8089"

  #---------------------------------
  # AutoNN: YoloE
  #---------------------------------
  # autonn_yoloe:
  #   build:
  #     context: ./autonn/YoloE
  #   shm_size: "256M"
  #   ipc: host
  #   command: >
  #     sh -c "python manage.py pretrained_supernet &&
  #            python manage.py makemigrations &&
  #            python manage.py migrate &&
  #            python manage.py runserver 0.0.0.0:8090"
  #   # use the below lines commented out if you want to use gpu
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             capabilities:
  #               - gpu
  #               - utility
  #               - compute
  #               - video
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=${GPU_NUM:-all}
  #   volumes:
  #     - ./autonn/YoloE:/source
  #     - shared:/shared
  #     - ./autonn/YoloE/sample_yaml/dataset.yaml:/shared/datasets/coco/dataset.yaml # TEMP FILE UNTIL LABELLING MODULE WORKING
  #     - ${COCODIR:-./autonn/YoloE/sample_data/coco128}:/shared/datasets/coco # TEMP FILE UNTIL LABELLING MODULE WORKING
  #   hostname: yoloe
  #   ports:
  #     - "8090:8090"

  #---------------------------------
  # AutoNN: ResNet
  #---------------------------------
  # autonn_resnet:
  #   build:
  #     context: ./autonn/ResNet
  #   shm_size: "256M"
  #   ipc: host
  #   command: >
  #     sh -c "python manage.py makemigrations &&
  #            python manage.py migrate &&
  #            python manage.py runserver 0.0.0.0:8092"
  #   # use the below lines commented out if you want to use gpu
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             capabilities:
  #               - gpu
  #               - utility
  #               - compute
  #               - video
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./autonn/ResNet:/source
  #     - shared:/shared
  #   hostname: autonn-resnet
  #   ports:
  #     - "8092:8092"

  #---------------------------------
  # code_gen Build
  #---------------------------------
  code_gen:
    build:
      context: ./deploy_codegen/optimize_codegen
    hostname: codeGen
    volumes:
      - ./deploy_codegen/optimize_codegen:/source
      - shared:/tango
    command: >
      sh -c "cd /app && python3 code_gen.py"
    ports:
      - 8888:8888

  #---------------------------------
  # Cloud deploy (with target image build)
  #---------------------------------
  cloud_deploy:
    hostname: cloud-deploy
    build:
      context: ./deploy_targets/cloud
    # -- command is not requred in favor of s6-overlay supervisor
    # command: >
    #   sh -c "python main.py"
    environment:
      - CLOUD_MANAGER_PORT=8088
      # GCP auth settings
      - GOOGLE_APPLICATION_CREDENTIALS=/source/cloud_manager/service-account-file.json
      - GCP_REGION=asia-northeast3
      - GCP_PROJECT_ID=tango-project
    volumes:
      - ./deploy_targets/cloud:/source
      - /var/run/docker.sock:/var/run/docker.sock
      - shared:/shared
    ports:
      - "7007:7007" # image builder (API)
      - "8080:8080" # image builder (GUI)
      - "8890:8890" # cloud manager

  #---------------------------------
  # K8S deploy
  #---------------------------------
  # kube_deploy:
  #   hostname: kube-deploy
  #   build:
  #     context: ./deploy_targets/k8s
  #   container_name: "tango_k8s"
  #   privileged: true
  #   command: bash -c "cd /app && python3 k8s_deploy.py"
  #   volumes:
  #     - $HOME/.kube:/home/root/.kube
  #     - shared:/app/tango
  #     - ./deploy_targets/k8s:/app
  #     - /var/run/docker.sock:/var/run/docker.sock
  #   environment:
  #     - "HOME=/home/root"
  #   ports:
  #     - "8901:8901"

  #---------------------------------
  # K8S docker registry(image manager)
  #---------------------------------
  # registry:
  #   image: registry
  #   container_name: registry
  #   volumes:
  #     - registry_data:/var/lib/registry/docker/registry/v2
  #   ports:
  #     - "8903:5000"

  #---------------------------------
  # ondevice_deploy Build
  #---------------------------------
  ondevice_deploy:
    hostname: ondevice
    build:
      context: ./deploy_targets/ondevice
    volumes:
      - ./deploy_targets/ondevice:/source
      - shared:/tango
    command: >
      sh -c "cd /app && python3 ondevice_deploy.py"
    ports:
      - 8891:8891
  #---------------------------------
  # Visualizer
  #---------------------------------
  # viz2code:
  #   hostname: viz2code
  #   build:
  #     context: ./visualization
  #   command: >
  #     sh -c "cd ./visualization/frontend &&
  #            npm run build &&
  #            cd ..
  #            python manage.py makemigrations &&
  #            python manage.py migrate &&
  #            python manage.py runserver react 0.0.0.0:8091"
  #   volumes:
  #     - ./visualization:/source
  #     - shared:/shared
  #   ports:
  #     - "8091:8091"
  # #   depends_on:
  # #     - postgresql

  #---------------------------------
  # Volumes
  #---------------------------------
volumes:
  registry_data: {}
  postgreSQL: # for Proejct Manager
  shared: # shared Directory
