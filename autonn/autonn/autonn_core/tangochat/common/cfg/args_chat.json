{
    "model": "llama3.1",
    "model_directory": "/shared/models/",

    "prompt": null,
    "image_prompts": null,
    "chat": false,
    "gui": false,
    "num_samples": 100,
    "max_new_tokens": 100,
    "top_k": 200,
    "temperature": 1.0,
    "compile": false,
    "compile_prefill": false, 
    "speculate_k": 100,
    "sequential_prefill": false,
    "max_autotune": false,

    "checkpoint_dir": null,
    "checkpoint_path": null,
    "dcp_dir": null,
    "params_path": null,
    "params_table": null,
    "gguf_path": null,
    "gguf_kwargs": null,
    "dso_path": null,
    "pte_path": null,
    "device": "cuda",
    "dtype": "half",
    "output_pte_path": null,
    "output_dso_path": null,
    "distributed": false,
    "is_chat_model": true,
    "dynamic_shapes": false,
    "max_seq_lengh": 250,
    "draft_checkpoint_path": null,
    "tokenizer_path": null,

    "profile": null,
    "quantize": false,
    "draft_quantize": false
}